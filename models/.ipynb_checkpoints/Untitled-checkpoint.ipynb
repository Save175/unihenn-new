{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbe19094-a34c-479b-8e79-b5b0d45a7a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.evasion import UniversalPerturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e98df05b-5d7d-4982-a258-4487862c5da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.attacks.evasion import UniversalPerturbation\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0671e64d-549b-4e45-8efe-408d2b929428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _approximated_ReLU(x):\n",
    "    return 0.117071 * x**2 + 0.5 * x + 0.375373\n",
    "\n",
    "class Square(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x**2\n",
    "\n",
    "class ApproxReLU(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return _approximated_ReLU(x)\n",
    "\n",
    "class Flatten(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.flatten(x, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b770ccc-a0ce-4917-a32b-f26657f1453e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class M5(torch.nn.Module):\n",
    "    def __init__(self, output=10):\n",
    "        super(M5, self).__init__()\n",
    "        # L1 Image shape=(?, 32, 32, 1)\n",
    "        #    Conv     -> (?, 30, 30, 16)\n",
    "        #    Pool     -> (?, 15, 15, 16)\n",
    "        self.Conv1 = torch.nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=0)\n",
    "        self.Square1 = Square()\n",
    "        self.AvgPool1 = torch.nn.AvgPool2d(kernel_size = 2)\n",
    "        # L2 Image shape=(?, 15, 15, 16)\n",
    "        #    Conv     -> (?, 12, 12, 64)\n",
    "        #    Pool     -> (?, 6, 6, 64)\n",
    "        self.Conv2 = torch.nn.Conv2d(in_channels=16, out_channels=64, kernel_size=4, stride=1, padding=0)\n",
    "        self.Square2 = Square()\n",
    "        self.AvgPool2 = torch.nn.AvgPool2d(kernel_size = 2)\n",
    "        # L2 Image shape=(?, 6, 6, 64)\n",
    "        #    Conv     -> (?, 4, 4, 128)\n",
    "        #    Pool     -> (?, 1, 1, 128)\n",
    "        self.Conv3 = torch.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=0)\n",
    "        self.Square3 = Square()\n",
    "        self.AvgPool3 = torch.nn.AvgPool2d(kernel_size = 4)\n",
    "        self.Flatten = Flatten()\n",
    "        self.FC1 = torch.nn.Linear(1*1*128, output)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.Conv1(x)\n",
    "        out = self.Square1(out)\n",
    "        out = self.AvgPool1(out)\n",
    "        out = self.Conv2(out)\n",
    "        out = self.Square2(out)\n",
    "        out = self.AvgPool2(out)\n",
    "        out = self.Conv3(out)\n",
    "        out = self.Square3(out)\n",
    "        out = self.AvgPool3(out)\n",
    "        out = self.Flatten(out)\n",
    "        out = self.FC1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f9071e4-6383-4170-992d-9f6806e7f07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./Data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████| 170498071/170498071 [00:18<00:00, 9196299.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./Data/cifar-10-python.tar.gz to ./Data\n",
      "Files already downloaded and verified\n",
      "train dataset: (50000, 32, 32, 3)\n",
      "test dataset : (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_epochs = 30\n",
    "batch_size = 32\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./Data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.CIFAR10(root= './Data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "print(\"train dataset:\", train_dataset.data.shape)\n",
    "print(\"test dataset :\", test_dataset.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68fc1454-1b1b-401c-a073-643cd9b70b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_numpy_data(loader):\n",
    "    x_list, y_list = [], []\n",
    "    for data, target in loader:\n",
    "        x_list.append(data.numpy())\n",
    "        y_list.append(target.numpy())\n",
    "\n",
    "    x_array = np.concatenate(x_list)\n",
    "    y_array = np.concatenate(y_list)\n",
    "    return x_array, y_array\n",
    "\n",
    "# Get NumPy arrays for training data\n",
    "x_train, y_train = get_numpy_data(train_loader)\n",
    "\n",
    "# Get NumPy arrays for test data\n",
    "x_test, y_test = get_numpy_data(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "86c4e78c-3a80-4724-8844-c869fd0964da",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load model checkpoint\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/user/Desktop/training/concreteml/M5_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Define model class before loading\u001b[39;00m\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m M5()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/serialization.py:1025\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1024\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1025\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(opened_zipfile,\n\u001b[1;32m   1026\u001b[0m                      map_location,\n\u001b[1;32m   1027\u001b[0m                      pickle_module,\n\u001b[1;32m   1028\u001b[0m                      overall_storage\u001b[38;5;241m=\u001b[39moverall_storage,\n\u001b[1;32m   1029\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[1;32m   1031\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/serialization.py:1446\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1444\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1445\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1446\u001b[0m result \u001b[38;5;241m=\u001b[39m unpickler\u001b[38;5;241m.\u001b[39mload()\n\u001b[1;32m   1448\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1449\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_metadata(\n\u001b[1;32m   1450\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load.metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialization_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: zip_file\u001b[38;5;241m.\u001b[39mserialization_id()}\n\u001b[1;32m   1451\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/serialization.py:1439\u001b[0m, in \u001b[0;36m_load.<locals>.UnpicklerWrapper.find_class\u001b[0;34m(self, mod_name, name)\u001b[0m\n\u001b[1;32m   1437\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1438\u001b[0m mod_name \u001b[38;5;241m=\u001b[39m load_module_mapping\u001b[38;5;241m.\u001b[39mget(mod_name, mod_name)\n\u001b[0;32m-> 1439\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfind_class(mod_name, name)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load model checkpoint\n",
    "checkpoint = torch.load('/home/user/Desktop/training/concreteml/M5_model.pth')\n",
    "\n",
    "# Define model class before loading\n",
    "model = M5()\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "# Define test function\n",
    "def test(model, test_loader, criterion):\n",
    "    test_loss = 0.0\n",
    "    class_correct = [0.0] * 10\n",
    "    class_total = [0.0] * 10\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():  # No need for gradients in testing\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            _, pred = torch.max(output, 1)\n",
    "            correct = pred.eq(target.view_as(pred)).cpu().numpy()\n",
    "\n",
    "            for i in range(len(target)):\n",
    "                label = target[i].item()\n",
    "                class_correct[label] += correct[i]\n",
    "                class_total[label] += 1\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    print(f'Test Loss: {test_loss:.6f}\\n')\n",
    "\n",
    "    # Print accuracy for each class\n",
    "    for label in range(10):\n",
    "        if class_total[label] > 0:  # Avoid division by zero\n",
    "            accuracy = 100 * class_correct[label] / class_total[label]\n",
    "            print(f'Test Accuracy of {label}: {int(accuracy)}% ({int(class_correct[label])}/{int(class_total[label])})')\n",
    "\n",
    "    # Overall accuracy\n",
    "    overall_accuracy = 100 * sum(class_correct) / sum(class_total)\n",
    "    print(f'\\nTest Accuracy (Overall): {int(overall_accuracy)}% ({int(sum(class_correct))}/{int(sum(class_total))})')\n",
    "\n",
    "# Run test\n",
    "test(model, test_loader, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50018885-7711-46b4-b003-d5a2b50b8ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1eb2f6-8cca-4cf0-ab34-12effdb1ec80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
